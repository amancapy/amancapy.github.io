<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Neural Networks - Samsarsa</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="Welcome.html"><strong aria-hidden="true">1.</strong> Welcome!</a></li><li class="chapter-item expanded "><a href="components.html"><strong aria-hidden="true">2.</strong> Components</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="physics.html"><strong aria-hidden="true">2.1.</strong> The Physics Engine</a></li><li class="chapter-item expanded "><a href="GA.html"><strong aria-hidden="true">2.2.</strong> Genetic Algorithms</a></li><li class="chapter-item expanded "><a href="beings.html"><strong aria-hidden="true">2.3.</strong> Beings' Sense-Actions</a></li><li class="chapter-item expanded "><a href="nns.html" class="active"><strong aria-hidden="true">2.4.</strong> Neural Networks</a></li></ol></li><li class="chapter-item expanded "><a href="considerations.html"><strong aria-hidden="true">3.</strong> Considerations and Limitations</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Samsarsa</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="neural-networks"><a class="header" href="#neural-networks">Neural Networks</a></h1>
<p>I used the <a href="https://burn.dev/">Burn</a> crate for all the neural network operations. I was hung up on how I should go about implementing the NNs for a really long time, and it was a major reason for my temprarily abandoning the project. Burn is quite good, and really fast!</p>
<p>Currently, I have two yes/no choices for how a neural network is constructed, giving us four architectures. I plan to add more in the future, but the computation is quite costly, and it's a tradeoff of how fast you want the algorithm to run and iterate through generations, versus how sophisticated you want the NN architecture itself to be.</p>
<p>If you are not at least a little bit comfortable with deep learning and neural networks, this may be a bit hard to follow. But I will try to explain as abstractly as will let me preserve coherence.</p>
<img id="being_nn_img" width="100%" src="./graphics/being_nn.svg">
<h2 id="1-choice-of-aggregator-function"><a class="header" href="#1-choice-of-aggregator-function">1. Choice of <em>aggregator</em> function</a></h2>
<p>You remember our arrays containing all the inputs, one each for each input type. Naturally, during the course of a being's interaction with the world, depending on where it is among other things, the lengths of these arrays will vary. If nobody's feeling talkative, the <code>speech_inputs</code> array will be empty, for example.</p>
<p>How do you take these varying-length arrays, and map them to a single vector? I made two different maps, with <em>vastly</em> different computational costs.</p>
<p>Now, there is one crucial requirement that a prospect aggregator function must satisfy: Its output should remain the same no matter how the input array is "ordered" (permutated). That is, <code>aggr([1, 2])</code> should be exactly equal to <code>aggr([2, 1])</code>. This is a very strong constraint (called permutation-invariance), and it is difficult to design functions that meet it without making some sacrifices.</p>
<h3 id="sumfx"><a class="header" href="#sumfx"><code>sum(f(x))</code></a></h3>
<ul>
<li>
<p>Consider our <code>being_inputs</code> array from <a href="./beings.html">the beings page</a>:</p>
<pre><code class="language-py">{[2., 3.4, 5.234], [1.34, 2.163, 9.67], ...}
</code></pre>
</li>
<li>
<p>The inner vectors are <code>3</code> long, so we say that the array has shape <code>(N, 3)</code>.</p>
</li>
<li>
<p>Consider a neural network <code>f</code> that has an input size of <code>3</code>, and an output size of <code>m</code>. All this means is that it takes <code>3</code>-long vectors, and returns <code>m</code>-long vectors.</p>
</li>
<li>
<p>Now, each of the input vectors in our array, we run through <code>f</code>, and collect <code>f</code>'s outputs in a different array. Naturally, this new array will have shape <code>(N, m)</code>.</p>
</li>
<li>
<p>Now, we sum this <code>(N, m)</code> array along the first dimension: If our array was</p>
<pre><code class="language-py">{[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]}
</code></pre>
<p>after running the original <code>being_inputs</code> array through <code>f</code>, then after performing this sum operation, it becomes a single vector, <code>[15, 18, 21, 24]</code>, of shape <code>(1, m)</code>.</p>
</li>
<li>
<p>You might have caught the drawback here. When we run <code>f</code> over each input separately, we don't account for how assessing one input might benefit from taking into consideration some other input. For example, if you notice food, but also that it is completely surrounded by walls, you will conclude that there is no point reaching for it. But if you assess the food and the walls completely in isolation, there is no way you can make this seemingly correct inference.</p>
</li>
</ul>
<h3 id="self-attention"><a class="header" href="#self-attention">Self-Attention</a></h3>
<p>I implemented, if poorly, <a href="https://arxiv.org/abs/1810.00825">Set-Transformers</a>! I will give a simple overview. But you should acquaint yourself with <a href="https://arxiv.org/abs/1706.03762">the self-attention mechanism</a>, if this is to fully make sense.</p>
<ul>
<li>
<p>In its essence, an attention function operates on two input vectors: a "key" vector and a "query" vector, and produces a measure, usually a single number (called a weight), for how relevant it thinks the query vector is in the assessment of the key vector.</p>
</li>
<li>
<p>When given an entire array of inputs, like our arrays, for each of the inputs,</p>
<ul>
<li>it fixes the current input as the key vector.</li>
<li>every other vector in the array, one at a time, it treats as the query vector, and produces an array of weights.</li>
<li>using these weights, it aggregates these weighted query vectors into a single vector, not unlike the previous <code>sum(f(x))</code>, and produces a single vector to add to our key vector.</li>
<li>After this is done for every single vector in our array, <em>now</em> we perform our <code>sum(f(x))</code>. But you see how the function <code>f</code> here is vastly more sophisticated, since it takes into account all the rest of the array, when previously, it depended only on the given input.</li>
</ul>
</li>
</ul>
<p>But you might have noticed the issue: key-query business is extremely expensive! Whereas sumfx's computational load was proportional to the length of our arrays, using attention as our aggregator instead is proportional to the <em>square</em> of the length. This is quite unconscionable if we're working with humble little machines like I am, without gigantic GPUs.</p>
<p>Anyway, this single vector of shape <code>(1, m)</code>, we use downstream in our bigger neural network, by in some form combining it with the other <code>(1, ...)</code> vectors produced for the other forms of input, before coming up with our final being output.</p>
<p>The way that I am currently doing it is, after we've performed the above for all kinds of vector, being, food, wall, speech, we concatenate the final <code>(1, ...)</code> vectors along the first axis, yielding <code>(1, m + n + o + p)</code>, a fairly long vector, that we finally map to our desired output (actions + speech vector as discussed in <a href="./beings.html">the beings section</a>) shape using another little neural network.</p>
<h2 id="2-whether-the-nn-remembers-the-past"><a class="header" href="#2-whether-the-nn-remembers-the-past">2. Whether the NN remembers the past</a></h2>
<p>Once done with the previous <em>aggregation</em> portion of sense-action we have a choice to either discard past inputs, or take them into consideration, as-is (as Transformers do), or in a summarized form (see <a href="https://www.bioinf.jku.at/publications/older/2604.pdf">LSTMs</a> for example). Now if we were to use gradient descent, this would get more complicated since we would have to include the "time" aspect of it into our backpropagation (but even that has been buried under like 20 years of library abstractions).</p>
<p>So far, I have only implemented LSTMs for past-processing. Transformers would work too, but as we saw before, the computation costs are huge, and also, remember permutation-invariance? Whereas it was indispensible before, it's actually a hurdle now! Because when looking back into the past, the order in which things happened is incredibly important! So much work goes into <em>un</em>doing this permutation-invariance to put Transformers to use in sentence-modelling (all the rage these days). And of course, the <code>n^2</code> computation cost too.</p>
<p>I will not get into how an LSTM works here. They are a variant of <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a>. The original paper I have linked above too is rather dense, and a lot of the design choices are rather arbitrary too in my opinion. But essentially,</p>
<p>When an RNN is given an input <code>x</code>, there are two consequences:</p>
<ul>
<li>Like in traditional "feed-forward" NNs, there is an output <code>y</code> produced by the processing of <code>x</code>.</li>
<li>Additionally, unlike FFNNs, there is an updation in the "internal state" of the RNN during the processing of <code>x</code>.</li>
</ul>
<p>This means that <code>x</code> will now have an impact on the processing of future <code>x</code>s as well. It has been "remembered" in a way; summarized into the RNN's memory. This summarization is usually done by smaller NNs that are sub-components of the RNN.</p>
<h2 id="possible-combinations"><a class="header" href="#possible-combinations">Possible combinations</a></h2>
<p>These choices give us four possible NN architectures:</p>
<ul>
<li><code>(sumfx, no-past)</code></li>
<li><code>(sumfx, lstm)</code></li>
<li><code>(self-attn, no-past)</code></li>
<li><code>(self-attn, lstm)</code></li>
</ul>
<p>This list also happens to occur in increasing order of computational load.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="beings.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="considerations.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="beings.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="considerations.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
